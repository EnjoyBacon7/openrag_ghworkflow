---
# GPU-enabled servers setup
- name: Setup OpenRAG Environment (GPU-enabled)
  hosts: gpu_servers
  become: true
  vars:
    # Version configurations
    docker_compose_version: "2.21.0"
    docker_ce_version: "latest"

    # Project configurations
    project_user: "{{ ansible_user | default('ubuntu') }}"
    project_path: "/home/{{ project_user }}/openrag"

    # System packages required for all installations
    common_packages:
      - apt-transport-https
      - ca-certificates
      - curl
      - gnupg
      - lsb-release
      - software-properties-common
      - wget
      - git
      - python3
      - python3-pip
      - unzip
      - htop
      - tree
      - vim

    # Docker packages
    docker_packages:
      - docker-ce
      - docker-ce-cli
      - containerd.io
      - docker-buildx-plugin
      - docker-compose-plugin

    # Project directories to create
    project_directories:
      - data
      - db
      - logs
      - .hydra_config
      - model_weights
      - vdb/volumes

    # GPU-specific configurations
    nvidia_driver_version: "535"
    nvidia_container_toolkit_version: "1.17.8-1"
    compose_profile: "" # Default GPU profile

  tasks:
    # ========== SYSTEM PREPARATION ==========
    - name: Update apt cache
      apt:
        update_cache: true
        cache_valid_time: 3600

    - name: Install required system packages
      apt:
        name: "{{ common_packages }}"
        state: present

    # ========== NVIDIA GPU VALIDATION ==========
    - name: Check if NVIDIA GPU is present
      shell: lspci | grep -i nvidia
      register: nvidia_check
      failed_when: false
      changed_when: false

    - name: Fail if no NVIDIA GPU found on GPU server
      fail:
        msg: "No NVIDIA GPU found on this server, but it's configured as a GPU server"
      when: nvidia_check.rc != 0

    # ========== NVIDIA DRIVER MANAGEMENT ==========

    - name: Check current NVIDIA driver version
      shell: |
        if command -v nvidia-smi >/dev/null 2>&1; then
          nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1
        else
          echo "not_installed"
        fi
      register: current_nvidia_version
      failed_when: false
      changed_when: false

    - name: Display current NVIDIA driver status
      debug:
        msg: "Current NVIDIA driver: {{ current_nvidia_version.stdout | default('not detected') }}, Required: {{ nvidia_driver_version }}"

    - name: Check if NVIDIA driver version matches requirement
      set_fact:
        nvidia_version_matches: "{{ current_nvidia_version.stdout.split('.')[0] == nvidia_driver_version }}"
      when: current_nvidia_version.stdout != "not_installed"

    - name: Set nvidia_version_matches to false if not installed
      set_fact:
        nvidia_version_matches: false
      when: current_nvidia_version.stdout == "not_installed"

    - name: Add NVIDIA package repository
      block:
        - name: Remove all NVIDIA and CUDA related packages
          apt:
            name:
              - nvidia-*
              - cuda-*
              - nsight-*
              - libnvidia-*
            state: absent
            purge: true
          ignore_errors: true

        - name: Remove held packages and fix broken dependencies
          shell: |
            apt-mark unhold $(apt-mark showhold)
            apt-get remove --purge -y nsight-systems-2023.2.3 || true
            apt-get autoremove -y
            apt-get autoclean
            dpkg --configure -a
            apt-get -f install -y
          ignore_errors: true

        - name: Download NVIDIA repository key
          get_url:
            url: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
            dest: /tmp/cuda-keyring_1.0-1_all.deb

        - name: Install NVIDIA repository key
          apt:
            deb: /tmp/cuda-keyring_1.0-1_all.deb

        - name: Update apt cache after adding NVIDIA repo
          apt:
            update_cache: true
      when: not nvidia_version_matches

    - name: Install NVIDIA drivers (without CUDA toolkit)
      block:
        - name: Install basic NVIDIA drivers
          apt:
            name:
              - nvidia-driver-{{ nvidia_driver_version }}
            state: present
            update_cache: true
          register: nvidia_basic_install
          ignore_errors: true

        - name: Install NVIDIA DKMS if basic install succeeded
          apt:
            name:
              - nvidia-dkms-{{ nvidia_driver_version }}
            state: present
          when: not nvidia_basic_install.failed
          ignore_errors: true

        - name: Try alternative NVIDIA driver installation
          shell: |
            apt-get install -y nvidia-driver-535-server nvidia-utils-535-server
          when: nvidia_basic_install.failed
          ignore_errors: true
      when: not nvidia_version_matches

    - name: Check NVIDIA driver status and handle reboot if needed
      block:
        - name: Initial NVIDIA driver check
          shell: nvidia-smi
          register: nvidia_initial_check
          ignore_errors: true
          changed_when: false

        - name: Check if driver/library version mismatch exists
          shell: nvidia-smi 2>&1 || true
          register: nvidia_output
          changed_when: false

        - name: Reboot system if NVIDIA driver requires it (only if we changed drivers)
          reboot:
            msg: "Rebooting to complete NVIDIA driver installation"
            reboot_timeout: 300
            connect_timeout: 30
          when:
            - not nvidia_version_matches
            - "'Driver/library version mismatch' in nvidia_output.stdout"

        - name: Wait for system to come back online after reboot
          wait_for_connection:
            delay: 30
            timeout: 300
          when:
            - not nvidia_version_matches
            - "'Driver/library version mismatch' in nvidia_output.stdout"

        - name: Final NVIDIA driver verification
          shell: nvidia-smi
          register: nvidia_final_check
          ignore_errors: true
          changed_when: false

        - name: Display NVIDIA driver status
          debug:
            msg: "NVIDIA driver: {{ 'Version matches requirement (' + nvidia_driver_version + ') - No changes needed' if nvidia_version_matches else ('Installation: ' + ('SUCCESS' if nvidia_final_check.rc == 0 else 'FAILED - May require manual reboot')) }}"

    # ========== DOCKER INSTALLATION ==========
    - name: Check current Docker version
      shell: |
        if command -v docker >/dev/null 2>&1; then
          docker --version | grep -oP 'Docker version \K[0-9]+\.[0-9]+\.[0-9]+'
        else
          echo "not_installed"
        fi
      register: current_docker_version
      failed_when: false
      changed_when: false

    - name: Display current Docker status
      debug:
        msg: "Current Docker: {{ current_docker_version.stdout | default('not detected') }}, Required: {{ docker_ce_version }}"

    - name: Check if Docker installation is needed
      set_fact:
        docker_installation_needed: "{{ docker_ce_version == 'latest' or current_docker_version.stdout == 'not_installed' or current_docker_version.stdout != docker_ce_version }}"

    - name: Clean Docker installation (if needed)
      block:
        - name: Uninstall old Docker versions
          apt:
            name:
              - docker.io
              - docker-doc
              - docker-compose
              - docker-compose-v2
              - podman-docker
              - containerd
              - runc
              - docker-ce
              - docker-ce-cli
            state: absent
            purge: true
          ignore_errors: true

        - name: Remove Docker repository and key files
          file:
            path: "{{ item }}"
            state: absent
          loop:
            - /etc/apt/sources.list.d/docker.list
            - /etc/apt/sources.list.d/docker.list.save
            - /etc/apt/sources.list.d/download_docker_com_linux_ubuntu.list
            - /usr/share/keyrings/docker-archive-keyring.gpg
            - /etc/apt/keyrings/docker.gpg
            - /etc/apt/keyrings/docker.asc
            - /etc/apt/trusted.gpg.d/docker.gpg
          ignore_errors: true

        - name: Clean Docker references and update cache
          shell: |
            sed -i '/download.docker.com/d' /etc/apt/sources.list
            sed -i '/docker/d' /etc/apt/sources.list
            apt-key del 9DC858229FC7DD38854AE2D88D81803C0EBFCD88 2>/dev/null || true
            apt-key del 0EBFCD88 2>/dev/null || true
          ignore_errors: true

        - name: Update apt cache after cleanup
          apt:
            update_cache: true
            autoclean: true
            autoremove: true
      when: docker_installation_needed

    - name: Install Docker (if needed)
      block:
        - name: Install Docker prerequisites
          apt:
            name: [ca-certificates, curl]
            state: present
            update_cache: true

        - name: Create keyrings directory
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: "0755"

        - name: Add Docker GPG key and repository
          shell: |
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
            chmod a+r /etc/apt/keyrings/docker.asc
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null

        - name: Update apt cache and install Docker
          apt:
            update_cache: true
            name: "{{ docker_packages }}"
            state: present
      when: docker_installation_needed

    - name: Start and enable Docker service
      systemd:
        name: docker
        state: started
        enabled: true

    - name: Add user to docker group
      user:
        name: "{{ project_user }}"
        groups: docker
        append: true

    # ========== NVIDIA CONTAINER TOOLKIT ==========
    - name: Check current NVIDIA Container Toolkit version
      shell: |
        if command -v nvidia-ctk >/dev/null 2>&1; then
          nvidia-ctk --version | grep -oP 'version \K[0-9]+\.[0-9]+\.[0-9]+'
        else
          echo "not_installed"
        fi
      register: current_nvidia_ctk_version
      failed_when: false
      changed_when: false

    - name: Display current NVIDIA Container Toolkit status
      debug:
        msg: "Current NVIDIA Container Toolkit: {{ current_nvidia_ctk_version.stdout | default('not detected') }}, Required: {{ nvidia_container_toolkit_version }}"

    - name: Check if NVIDIA Container Toolkit installation is needed
      set_fact:
        nvidia_ctk_installation_needed: "{{ current_nvidia_ctk_version.stdout == 'not_installed' or current_nvidia_ctk_version.stdout != nvidia_container_toolkit_version.split('-')[0] }}"

    - name: Clean NVIDIA Container Toolkit installation (if needed)
      block:
        - name: Remove existing NVIDIA container repositories
          file:
            path: "{{ item }}"
            state: absent
          loop:
            - /etc/apt/sources.list.d/libnvidia-container.list
            - /etc/apt/sources.list.d/nvidia-docker.list
            - /etc/apt/sources.list.d/nvidia-container-runtime.list
            - /etc/apt/sources.list.d/nvidia-container-toolkit.list
            - /etc/apt/sources.list.d/nvidia-container-toolkit.list.save
            - /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
            - /etc/apt/keyrings/nvidia-container-toolkit.gpg
            - /etc/apt/trusted.gpg.d/nvidia-container-toolkit.gpg
          ignore_errors: true

        - name: Clean NVIDIA container references
          shell: |
            sed -i '/nvidia.github.io\/libnvidia-container/d' /etc/apt/sources.list
            apt-key del $(apt-key list 2>/dev/null | grep -A1 "nvidia" | grep -oE "[A-F0-9]{8}" | head -1) 2>/dev/null || true
          ignore_errors: true

        - name: Update apt cache
          apt:
            update_cache: true
            autoclean: true
          ignore_errors: true
      when: nvidia_ctk_installation_needed

    - name: Configure NVIDIA Container Toolkit repository
      shell: |
        curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
        curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
          sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
          tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
      when: nvidia_ctk_installation_needed

    - name: Install NVIDIA Container Toolkit packages
      apt:
        update_cache: true
        name:
          - nvidia-container-toolkit={{ nvidia_container_toolkit_version }}
          - nvidia-container-toolkit-base={{ nvidia_container_toolkit_version }}
          - libnvidia-container-tools={{ nvidia_container_toolkit_version }}
          - libnvidia-container1={{ nvidia_container_toolkit_version }}
        state: present
      when: nvidia_ctk_installation_needed

    - name: Configure NVIDIA Container Runtime for Docker
      block:
        - name: Configure container runtime using nvidia-ctk
          shell: nvidia-ctk runtime configure --runtime=docker

        - name: Restart Docker service to apply NVIDIA runtime
          systemd:
            name: docker
            state: restarted
      when: nvidia_ctk_installation_needed or ansible_run_tags is defined and 'nvidia-config' in ansible_run_tags

    # Project Setup
    - name: Create project directory
      file:
        path: "{{ project_path }}"
        state: directory
        owner: "{{ project_user }}"
        group: "{{ project_user }}"
        mode: "0755"

    - name: Clone or update OpenRAG repository
      git:
        repo: https://github.com/linagora/openrag.git
        dest: "{{ project_path }}"
        force: true
      become_user: "{{ project_user }}"

    - name: Setup environment file
      block:
        - name: Check if .env file exists
          stat:
            path: "{{ project_path }}/.env"
          register: env_file

        - name: Check if local .env file exists (in playbook directory)
          stat:
            path: "{{ playbook_dir }}/.env"
          register: local_env_file
          delegate_to: localhost
          become: false

        - name: Copy local .env file to project directory if it exists
          copy:
            src: "{{ playbook_dir }}/.env"
            dest: "{{ project_path }}/.env"
            owner: "{{ project_user }}"
            group: "{{ project_user }}"
            mode: "0644"
          when:
            - not env_file.stat.exists
            - local_env_file.stat.exists

        - name: Copy .env.example to .env if neither local nor project .env exists
          copy:
            src: "{{ project_path }}/.env.example"
            dest: "{{ project_path }}/.env"
            remote_src: true
            owner: "{{ project_user }}"
            group: "{{ project_user }}"
            mode: "0644"
          when:
            - not env_file.stat.exists
            - not local_env_file.stat.exists
      become_user: "{{ project_user }}"

    - name: Create required directories
      file:
        path: "{{ project_path }}/{{ item }}"
        state: directory
        owner: "{{ project_user }}"
        group: "{{ project_user }}"
        mode: "0755"
      loop:
        - data
        - db
        - logs
        - .hydra_config
        - model_weights
        - vdb/volumes
      become_user: "{{ project_user }}"

    - name: Setup Python environment
      block:
        - name: Install uv (Python package manager)
          shell: curl -LsSf https://astral.sh/uv/install.sh | sh
          args:
            creates: "/home/{{ project_user }}/.cargo/bin/uv"

        - name: Add uv to PATH in .bashrc
          lineinfile:
            path: "/home/{{ project_user }}/.bashrc"
            line: 'export PATH="$HOME/.cargo/bin:$PATH"'
            create: true
      become_user: "{{ project_user }}"

    - name: Deploy and start OpenRAG services
      block:
        - name: Pre-pull Docker images
          shell: |
            cd {{ project_path }}
            docker compose pull
          ignore_errors: true

        - name: Build Docker images
          shell: |
            cd {{ project_path }}
            docker compose build

        - name: Start Docker Compose services (GPU profile)
          shell: |
            cd {{ project_path }}
            docker compose --profile "{{ compose_profile }}" up -d

        - name: Wait for Docker containers to be running and healthy
          shell: |
            cd {{ project_path }}
            # Wait for containers to start and stabilize
            sleep 30
            # Check if containers are running
            running_containers=$(docker compose ps --services --filter "status=running" | wc -l)
            total_containers=$(docker compose ps --services | wc -l)
            echo "Running containers: $running_containers/$total_containers"
            if [ $running_containers -gt 0 ]; then
              exit 0
            else
              exit 1
            fi
          register: container_health
          retries: 10
          delay: 30
          until: container_health.rc == 0
          ignore_errors: true
      become_user: "{{ project_user }}"

    # Verification and Testing
    - name: Verify deployment and test NVIDIA integration
      block:
        - name: Check Docker containers status
          shell: docker ps --format "table {{ '{{.Names}}' }}\t{{ '{{.Status}}' }}\t{{ '{{.Ports}}' }}"
          register: docker_status

        - name: Display running containers
          debug:
            var: docker_status.stdout_lines

        - name: Test NVIDIA Docker integration
          shell: docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi
          register: nvidia_test
          ignore_errors: true

        - name: Test NVIDIA Docker integration with alternative runtime flag
          shell: docker run --rm --gpus all ubuntu nvidia-smi
          register: nvidia_test_fallback
          ignore_errors: true
          when: nvidia_test.rc != 0

        - name: Display NVIDIA test result
          debug:
            var: "{{ nvidia_test.stdout_lines if nvidia_test.rc == 0 else nvidia_test_fallback.stdout_lines }}"
          when: nvidia_test.rc == 0 or nvidia_test_fallback.rc == 0

        - name: Display NVIDIA test failure if all attempts failed
          debug:
            msg:
              - "NVIDIA Docker integration test failed with all attempts"
              - "Runtime flag error: {{ nvidia_test.stderr }}"
              - "GPUs flag error: {{ nvidia_test_fallback.stderr | default('Not attempted') }}"
              - "This usually indicates NVIDIA Container Toolkit is not properly configured"
          when: nvidia_test.rc != 0 and nvidia_test_fallback.rc != 0

        - name: Show service URLs
          debug:
            msg:
              - "OpenRAG API: http://{{ ansible_default_ipv4.address }}:8080"
              - "Ray Dashboard: http://{{ ansible_default_ipv4.address }}:8265"
              - "Milvus: {{ ansible_default_ipv4.address }}:19530"
      become_user: "{{ project_user }}"

- name: Setup OpenRAG Environment (CPU-only)
  hosts: cpu_servers
  become: true
  vars:
    # Version configurations
    docker_compose_version: "2.21.0"
    docker_ce_version: "latest"

    # Project configurations
    project_user: "{{ ansible_user | default('ubuntu') }}"
    project_path: "/home/{{ project_user }}/openrag"

    # System packages required for all installations
    common_packages:
      - apt-transport-https
      - ca-certificates
      - curl
      - gnupg
      - lsb-release
      - software-properties-common
      - wget
      - git
      - python3
      - python3-pip
      - unzip
      - htop
      - tree
      - vim

    # Docker packages
    docker_packages:
      - docker-ce
      - docker-ce-cli
      - containerd.io
      - docker-buildx-plugin
      - docker-compose-plugin

    # Project directories to create
    project_directories:
      - data
      - db
      - logs
      - .hydra_config
      - model_weights
      - vdb/volumes

    # CPU-specific configurations
    compose_profile: "cpu" # CPU profile

  tasks:
    - name: Update apt cache
      apt:
        update_cache: true
        cache_valid_time: 3600

    - name: Install required system packages
      apt:
        name: "{{ common_packages }}"
        state: present

    - name: Install Docker
      block:
        - name: Completely remove Docker and repository configurations
          block:
            - name: Uninstall old Docker versions
              apt:
                name:
                  - docker.io
                  - docker-doc
                  - docker-compose
                  - docker-compose-v2
                  - podman-docker
                  - containerd
                  - runc
                  - docker-ce
                  - docker-ce-cli
                state: absent
                purge: true
              ignore_errors: true

            - name: Remove all Docker-related repository and key files
              file:
                path: "{{ item }}"
                state: absent
              loop:
                - /etc/apt/sources.list.d/docker.list
                - /etc/apt/sources.list.d/docker.list.save
                - /etc/apt/sources.list.d/download_docker_com_linux_ubuntu.list
                - /usr/share/keyrings/docker-archive-keyring.gpg
                - /etc/apt/keyrings/docker.gpg
                - /etc/apt/keyrings/docker.asc
                - /etc/apt/trusted.gpg.d/docker.gpg
              ignore_errors: true

            - name: Clean any Docker references from main sources.list
              shell: |
                sed -i '/download.docker.com/d' /etc/apt/sources.list
                sed -i '/docker/d' /etc/apt/sources.list
              ignore_errors: true

            - name: Remove Docker GPG keys from apt-key
              shell: |
                apt-key del 9DC858229FC7DD38854AE2D88D81803C0EBFCD88 2>/dev/null || true
                apt-key del 0EBFCD88 2>/dev/null || true
              ignore_errors: true

            - name: Clean apt cache and update
              apt:
                update_cache: true
                autoclean: true
                autoremove: true

        - name: Install Docker prerequisites
          apt:
            name:
              - ca-certificates
              - curl
            state: present
            update_cache: true

        - name: Create keyrings directory
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: "0755"

        - name: Add Docker's official GPG key
          shell: |
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
            chmod a+r /etc/apt/keyrings/docker.asc

        - name: Add Docker repository to Apt sources
          shell: |
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null

        - name: Update apt cache and install Docker packages
          apt:
            update_cache: true
            name: "{{ docker_packages }}"
            state: present

        - name: Start and enable Docker service
          systemd:
            name: docker
            state: started
            enabled: true

        - name: Add user to docker group
          user:
            name: "{{ project_user }}"
            groups: docker
            append: true

    # Project Setup
    - name: Create project directory
      file:
        path: "{{ project_path }}"
        state: directory
        owner: "{{ project_user }}"
        group: "{{ project_user }}"
        mode: "0755"

    - name: Clone or update OpenRAG repository
      git:
        repo: https://github.com/linagora/openrag.git
        dest: "{{ project_path }}"
        force: true
      become_user: "{{ project_user }}"

    - name: Setup environment file
      block:
        - name: Check if .env file exists
          stat:
            path: "{{ project_path }}/.env"
          register: env_file

        - name: Check if local .env file exists (in playbook directory)
          stat:
            path: "{{ playbook_dir }}/.env"
          register: local_env_file
          delegate_to: localhost
          become: false

        - name: Copy local .env file to project directory if it exists
          copy:
            src: "{{ playbook_dir }}/.env"
            dest: "{{ project_path }}/.env"
            owner: "{{ project_user }}"
            group: "{{ project_user }}"
            mode: "0644"
          when:
            - not env_file.stat.exists
            - local_env_file.stat.exists

        - name: Copy .env.example to .env if neither local nor project .env exists
          copy:
            src: "{{ project_path }}/.env.example"
            dest: "{{ project_path }}/.env"
            remote_src: true
            owner: "{{ project_user }}"
            group: "{{ project_user }}"
            mode: "0644"
          when:
            - not env_file.stat.exists
            - not local_env_file.stat.exists
      become_user: "{{ project_user }}"

    - name: Create required directories
      file:
        path: "{{ project_path }}/{{ item }}"
        state: directory
        owner: "{{ project_user }}"
        group: "{{ project_user }}"
        mode: "0755"
      loop:
        - data
        - db
        - logs
        - .hydra_config
        - model_weights
        - vdb/volumes
      become_user: "{{ project_user }}"

    - name: Setup Python environment
      block:
        - name: Install uv (Python package manager)
          shell: curl -LsSf https://astral.sh/uv/install.sh | sh
          args:
            creates: "/home/{{ project_user }}/.cargo/bin/uv"

        - name: Add uv to PATH in .bashrc
          lineinfile:
            path: "/home/{{ project_user }}/.bashrc"
            line: 'export PATH="$HOME/.cargo/bin:$PATH"'
            create: true
      become_user: "{{ project_user }}"

    - name: Deploy and start OpenRAG services
      block:
        - name: Pre-pull Docker images
          shell: |
            cd {{ project_path }}
            docker compose pull
          ignore_errors: true

        - name: Build Docker images
          shell: |
            cd {{ project_path }}
            docker compose build

        - name: Start Docker Compose services (CPU profile)
          shell: |
            cd {{ project_path }}
            docker compose --profile {{ compose_profile }} up -d

        - name: Wait for Docker containers to be running and healthy
          shell: |
            cd {{ project_path }}
            # Wait for containers to start and stabilize
            sleep 30
            # Check if containers are running
            running_containers=$(docker compose ps --services --filter "status=running" | wc -l)
            total_containers=$(docker compose ps --services | wc -l)
            echo "Running containers: $running_containers/$total_containers"
            if [ $running_containers -gt 0 ]; then
              exit 0
            else
              exit 1
            fi
          register: container_health
          retries: 10
          delay: 30
          until: container_health.rc == 0
          ignore_errors: true
      become_user: "{{ project_user }}"

    # Verification and Service URLs
    - name: Verify deployment and show service information
      block:
        - name: Check Docker containers status
          shell: docker ps --format "table {{ '{{.Names}}' }}\t{{ '{{.Status}}' }}\t{{ '{{.Ports}}' }}"
          register: docker_status

        - name: Display running containers
          debug:
            var: docker_status.stdout_lines

        - name: Show service URLs
          debug:
            msg:
              - "OpenRAG API: http://{{ ansible_default_ipv4.address }}:8080"
              - "Milvus: {{ ansible_default_ipv4.address }}:19530"
      become_user: "{{ project_user }}"
