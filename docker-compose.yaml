include:
  - vdb/milvus.yaml

x-ragondin: &ragondin_template
  build:
    context: .
    dockerfile: Dockerfile
  volumes:
    - ./.hydra_config:/app/.hydra_config
    - ${HF_MODEL_DIR:-~/.cache}/huggingface:/app/model_weights
    - ${DATALAB_MODEL_DIR:-~/.cache}/datalab:/root/.cache/datalab # marker model weights
    - ./data:/app/data
    - ./ragondin:/app/ragondin # For dev mode
    - ${MILVUS_VOLUME_DIRECTORY:-./volumes}:/app/volumes

  ports:
    - "${APP_PORT:-8080}:${APP_iPORT:-8080}"
    - ${RAY_DASHBOARD_PORT:-8265}:${RAY_DASHBOARD_PORT:-8265 # for ray dashboard

  env_file:
    - .env
  shm_size: 10.24gb

  depends_on:
    - milvus

services:
  # GPU - default 
  ragondin:
    <<: *ragondin_template
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    profiles:
      - '' # Empty string gives default behavior (but does not run when cpu requested)


  # No GPU (docker compose --profile cpu up --build)
  ragondin-cpu:
    <<: *ragondin_template
    deploy: {}
    profiles:
      - 'cpu'

  vllm:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all 
              capabilities: [gpu]
    environment:
      - HUGGING_FACE_HUB_TOKEN
    ipc: "host"
    volumes:
      - ./vllm_cache:/root/.cache/huggingface
    command: >
      --model ${EMBEDDER_MODEL_NAME:-jinaai/jina-embeddings-v3}
      --trust-remote-code
    ports:
      - ${VLLM_PORT:-8000}:8000