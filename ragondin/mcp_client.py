import os
import json
import asyncio
from typing import Dict, Any, List, Optional

import anthropic
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.client import MCPClient
from mcp.server.fastmcp import FastMCP

from .mcp_server import mcp_server

# Param√®tres du serveur MCP
server_params = StdioServerParameters(
    command="python",
    args=["-m", "ragondin.mcp_server"],
    env={"ANTHROPIC_API_KEY": os.environ.get("ANTHROPIC_API_KEY")}
)

# Client Anthropic
client = anthropic.Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))


async def run_rag_query(query: str, partition: Optional[str] = None) -> str:
    """Ex√©cute une requ√™te RAG en utilisant le serveur MCP et Anthropic Claude
    
    Args:
        query: La question de l'utilisateur
        partition: Partition sp√©cifique √† utiliser (optionnel)
        
    Returns:
        R√©ponse du mod√®le
    """
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Initialiser la connexion
            await session.initialize()
            
            # Chercher les documents pertinents
            filter_args = {}
            if partition:
                filter_args["partition"] = partition
                
            results_json = await session.call_tool(
                "search_documents", 
                arguments={
                    "query": query,
                    "top_k": 5,
                    "similarity_threshold": 0.75,
                    **({"partition": partition} if partition else {})
                }
            )
            
            # Parser les r√©sultats
            results = json.loads(results_json)
            
            if not results:
                return "Aucun document pertinent trouv√© pour cette requ√™te."
            
            # Obtenir le prompt RAG
            prompt_result = await session.get_prompt(
                "rag_prompt",
                arguments={
                    "query": query,
                    "context_documents": results
                }
            )
            
            # Appeler Anthropic Claude avec le prompt
            message = client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1000,
                system=prompt_result.get("system", ""),
                messages=prompt_result.get("messages", [])
            )
            
            return message.content[0].text


async def index_documents_with_mcp(
    path: str, 
    metadata: Optional[Dict[str, Any]] = None,
    partition: Optional[str] = None
) -> str:
    """Indexe des documents en utilisant le serveur MCP
    
    Args:
        path: Chemin vers les documents √† indexer
        metadata: M√©tadonn√©es √† associer (optionnel)
        partition: Partition √† utiliser (optionnel)
        
    Returns:
        R√©sultat de l'indexation
    """
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Initialiser la connexion
            await session.initialize()
            
            # Indexer les documents
            result_json = await session.call_tool(
                "index_documents",
                arguments={
                    "path": path,
                    **({"metadata": metadata} if metadata else {}),
                    **({"partition": partition} if partition else {})
                }
            )
            
            return result_json


async def list_partitions() -> List[str]:
    """Liste les partitions disponibles
    
    Returns:
        Liste des partitions
    """
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Initialiser la connexion
            await session.initialize()
            
            # Lire la ressource des partitions
            content, _ = await session.read_resource("indexation://partitions")
            return json.loads(content)


async def run_openai_query(prompt: str, model: str = "gpt-3.5-turbo", max_tokens: int = 1000) -> str:
    """Ex√©cute une requ√™te en utilisant l'API OpenAI via le MCP
    Args:
        prompt: Le prompt pour l'API OpenAI
        model: Le mod√®le √† utiliser
        max_tokens: Nombre maximum de tokens dans la r√©ponse
    Returns:
        R√©ponse g√©n√©r√©e par l'API OpenAI
    """
    async with MCPClient(mcp_server) as session:
        result = await session.call_tool("call_openai_api", prompt=prompt, model=model, max_tokens=max_tokens)
        return result


async def main():
    """Exemple d'utilisation de l'int√©gration MCP avec RAGondin et Anthropic Claude"""
    # V√©rification de la cl√© API Anthropic
    if not os.environ.get("ANTHROPIC_API_KEY"):
        print("‚ö†Ô∏è Veuillez d√©finir la variable d'environnement ANTHROPIC_API_KEY")
        return
    
    # Exemple: Indexer un document
    print("üìë Indexation d'un document...")
    result = await index_documents_with_mcp(
        path="./data/sample.txt",
        metadata={"source": "exemple", "auteur": "RAGondin"},
        partition="test"
    )
    print(f"R√©sultat de l'indexation: {result}")
    
    # Exemple: Lister les partitions
    print("\nüóÇÔ∏è Partitions disponibles:")
    partitions = await list_partitions()
    print(partitions)
    
    # Exemple: Requ√™te RAG
    print("\n‚ùì R√©ponse √† une question...")
    question = "Que contient le document sample.txt?"
    answer = await run_rag_query(question, partition="test")
    print(f"Question: {question}")
    print(f"R√©ponse: {answer}")


if __name__ == "__main__":
    asyncio.run(main()) 